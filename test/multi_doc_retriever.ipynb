{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AnZQpL_IZZZ"
      },
      "source": [
        "# LangChain multi-doc retriever with ChromaDB\n",
        "\n",
        "***New Points***\n",
        "- Multiple Files\n",
        "- ChromaDB\n",
        "- Source info\n",
        "- gpt-3.5-turbo API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      },
      "source": [
        "## Setting up LangChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DOT_ENV_PATH = \"/Users/danielgeorge/Documents/work/ml/hypolab/Synapse/backend/node/.env\"\n",
        "dotenv.load_dotenv(DOT_ENV_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UcQKUId3X2M"
      },
      "source": [
        "## Load multiple and process documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PRSeXXc_3Ypj"
      },
      "outputs": [],
      "source": [
        "# Load and process the text files\n",
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('./data', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJJmvNpbqfoq",
        "outputId": "af0af6fa-bcdd-4174-a107-6d380cb703e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='0123456789();: Artificial intelligence (AI) has been called \\na revolutionary tool for science1,2 and \\nit has been predicted to play a creative \\nrole in research in the future3. In the \\ncontext of theoretical chemistry, for example, it is believed that AI can help \\nsolve problems “in a way such that the human cannot distinguish between this [AI] and communicating with a human \\nexpert”\\n4. However, this excitement has not \\nbeen shared by all scientists. Some have questioned whether advanced computational \\napproaches can go beyond ‘numerics’\\n5–9 and \\ncontribute on a fundamental level to gaining \\nof new scientific understanding10–12.\\nIn this Perspective, we discuss how \\nadvanced computational systems, and AI \\nin particular, can contribute to scientific \\nunderstanding: we overview what is \\ncurrently possible and what might lie ahead. In addition to the review of the literature, we surveyed dozens of scientists working at \\nthe interface of biology, chemistry or physics \\non the one hand, and AI and advanced understood and generalized by human scientists. Third, AI acts as an agent of understanding. AI reaches new scientific \\ninsight and — importantly — can transfer it \\nto human researchers. Although there have not yet been any examples of AI acting as a true ‘agent of understanding’ in science, we \\noutline important characteristics of such  \\na system and discuss possible ways to \\nachieve it.\\nIn the first two dimensions, the AI \\nenables humans to gain new scientific understanding, whereas in the last, the machine gains understanding itself. Distinguishing between these classes \\nallows us to map out a vibrant and mostly \\nunexplored field of research, and will hopefully guide direction for future AI developments in the natural sciences.\\nThe focus of this Perspective is how \\nadvanced computational systems and AI specifically can contribute to new scientific understanding. There are \\nmany related, interesting topics that we \\ncannot cover here. For example, we will not discuss the relationship between scientific understanding and cognitive \\nscience, but refer the reader to a good \\noverview\\n14. Furthermore, we will only \\ndiscuss ‘understanding’ in the context of \\nthe natural sciences, in which we can use \\nconcrete criteria from the philosophy of science and, therefore, will not touch on ‘understanding’ in a broader context (such \\nas understanding by babies and animals, \\nlanguage understanding in AI and related topics). Many other works contribute to related questions and should be mentioned \\nhere. One important field of research in  \\nAI is explainable AI, which aims to \\ninterpret and explain how advanced AI algorithms come up with their solutions; \\nsee, for instance, \\nrefs.15–18. Whereas it is not \\nnecessary, and we believe also not sufficient, to interpret the internal workings of the \\nAI to get new scientific understanding, many of these tools and techniques can be very useful. We will briefly explain \\nthem below with concrete examples in the \\nnatural sciences. AI pioneer Donald Michie classified machine learning (ML) into three classes: weak, strong and ultrastrong, in \\nwhich ultrastrong requires the machine to \\nteach the human\\n19. The ultrastrong ML is \\nrelated to the idea of agent of understanding, computational methods on the other. These personal narratives (see Supplementary Information) focus on the concrete discovery process of ideas and are a vital \\naugmentation of the scientific literature. We \\ndiscuss the literature overview and personal accounts in the context of the philosophical theory of scientific understanding \\nrecently developed by Dennis Dieks and \\nHenk de Regt\\n12,13. We then identify three \\nfundamental dimensions for AI contributing \\nto new scientific understanding (fig.\\xa01). \\n(We encapsulate all advanced artificial computational systems under the term AI, \\nindependent of their working principles. In this way, we are focusing on the operational objective rather than the methodology.) First, AI can act as an instrument revealing properties of a physical system that are \\notherwise difficult or even impossible to \\nprobe. Humans then lift these insights to scientific understanding. Second, AI can act as a source of inspiration for new \\nconcepts and ideas that are subsequently On scientific understanding with \\nartificial intelligence\\nMario\\xa0Krenn, Robert\\xa0Pollice, Si\\xa0Yue\\xa0Guo, Matteo\\xa0Aldeghi, Alba\\xa0Cervera-Lierta, \\nPascal\\xa0Friederich, Gabriel\\xa0dos\\xa0Passos\\xa0Gomes, Florian\\xa0Häse, Adrian\\xa0Jinich, AkshatKumar\\xa0Nigam, Zhenpeng\\xa0Yao \\n  and Alán\\xa0Aspuru-Guzik  \\nAbstract | An oracle that correctly predicts the outcome of every particle physics \\nexperiment, the products of every possible chemical reaction or the function of \\nevery protein would revolutionize science and technology. However, scientists \\nwould not be entirely satisfied because they would want to comprehend how the \\noracle made these predictions. This is scientific understanding, one of the main \\naims of science. With the increase in the available computational power and \\nadvances in artificial intelligence, a natural question arises: how can advanced \\ncomputational systems, and specifically artificial intelligence, contribute to new \\nscientific understanding or gain it autonomously? Trying to answer this question, \\nwe adopted a definition of ‘scientific understanding’ from the philosophy of science that enabled us to overview the scattered literature on the topic and, \\ncombined with dozens of anecdotes from scientists, map out three dimensions of \\ncomputer-assisted scientific understanding. For each dimension, we review the \\nexisting state of the art and discuss future developments. We hope that this \\nPerspective will inspire and focus research directions in this multidisciplinary \\nemerging field.\\n  volume 4 | December 2022 | 761\\nPersPecTives\\nNature reviews | Physics', metadata={'source': 'data/Krenn et al. - 2022 - On scientific understanding with artificial intelligence  Nature Reviews Physics.pdf', 'page': 0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3__nT0D4Fkmg"
      },
      "outputs": [],
      "source": [
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlU5AlqY4gwj",
        "outputId": "b8a72e72-bca6-4458-cf30-f8ba8168dbe1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "164"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6-9jwU4ja_",
        "outputId": "a2061f09-61a8-42f1-d7e8-e30261b33257"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='language understanding in AI and related topics). Many other works contribute to related questions and should be mentioned \\nhere. One important field of research in  \\nAI is explainable AI, which aims to \\ninterpret and explain how advanced AI algorithms come up with their solutions; \\nsee, for instance, \\nrefs.15–18. Whereas it is not \\nnecessary, and we believe also not sufficient, to interpret the internal workings of the \\nAI to get new scientific understanding, many of these tools and techniques can be very useful. We will briefly explain \\nthem below with concrete examples in the \\nnatural sciences. AI pioneer Donald Michie classified machine learning (ML) into three classes: weak, strong and ultrastrong, in \\nwhich ultrastrong requires the machine to \\nteach the human\\n19. The ultrastrong ML is', metadata={'source': 'data/Krenn et al. - 2022 - On scientific understanding with artificial intelligence  Nature Reviews Physics.pdf', 'page': 0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsYsIy8F4cdm"
      },
      "source": [
        "## create the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Q_eTIZwf4Dk2"
      },
      "outputs": [],
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = 'db'\n",
        "\n",
        "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "outputs": [],
      "source": [
        "# persiste the db to disk\n",
        "vectordb.persist()\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A-h1y_eAHmD-"
      },
      "outputs": [],
      "source": [
        "# Now we can load the persisted database from disk, and use it as normal.\n",
        "vectordb = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siLXR-XT0JoI"
      },
      "source": [
        "## Make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cYA-H59u0Skn"
      },
      "outputs": [],
      "source": [
        "docs = retriever.get_relevant_documents(\"How would we use AAV to edit cells?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0iAuh_B0ZjE",
        "outputId": "7b412155-74b6-484c-c500-699eefa8c25f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H4N0IhRM0hHL",
        "outputId": "b478a6ad-f17f-4bf4-97f4-9cf941c0d653"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'similarity'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jXL9u-u0prF",
        "outputId": "3583ae2e-5bae-4efc-b40c-9b3ebf8a6252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'k': 2}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      },
      "source": [
        "## Make a chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfX4vX-5RFT",
        "outputId": "f05be533-f643-4f72-ae37-a2b5777df9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " AAV can be used to edit cells through a gene therapy or a passive vaccine. It can be produced in HEK293 cells using a platform of transient transfection or using baculovirus infection of Spodoptera frugiperda insect cells.\n",
            "\n",
            "\n",
            "Sources:\n",
            "data/data/Rumachik et al. - 2020 - Methods Matter Standard Production Platforms for.pdf\n",
            "data/data/Rumachik et al. - 2020 - Methods Matter Standard Production Platforms for.pdf\n"
          ]
        }
      ],
      "source": [
        "# full example\n",
        "query = \"How would we use AAV to edit cells?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRm73t3rNt2",
        "outputId": "e22e3e34-7519-4c29-bb01-b329425d2d99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Favorite representations\\n- notations (Leibniz), automata, graphs (Bret victor), car recliner button\\n- keep reading design of everyday things\\n- Going from 1 to 0 registers through analogy (Python)\\n- Mendeleev and the periodic table\\n',\n",
              " 'result': \" I don't know.\",\n",
              " 'source_documents': [Document(page_content='during the day. If yesterday you met three new people, and you \\nwere made aware of the fact today, you might feel pressure d to \\nmeet or exceed yesterday\\'s number. If you were not keeping track \\nof the daily number, yesterday\\'s achievement would have no \\npositive bearing on your actions today. Effectively this means that \\neven if the artifacts we design for augmenting aspects of cognition \\ndo not fun ction perfectly, we may get at least an initial \\nimprovement in  functionality purely based on this measurement \\nand increased awa reness phenomenon.  \\nPopulations  \\nUseful parallels with the biological sciences need not end with co -\\nevolution. In his 1962 paper, Engelbart lamented how \"each \\nindividual tends to evolve his own variations, but there is not \\nenough mutation and selection activ ity, nor enough selection \\nfeedback, to permit very significant changes.\" Fifty years later, if \\nwe can significantly extend  humans via software, we will create  a', metadata={'source': 'data/data/Xia and Maes - 2013 - The design of artifacts for augmenting intellect.pdf', 'page': 5}),\n",
              "  Document(page_content='1962]  in order to  (1) update Engelbart\\'s IA framework for \\npersonal wearable devices of the 21st century, (2) propose a \\nlogical design pattern for new IA devices (3) place existing IA \\nartifacts within conte xt, and in such a way to (4) identify IA areas \\nthat may benefit from additional research activity and \\nconceptualize new devices.  \\nEngelbart studied how augmentation could make humans better \\nproblem solvers. He chose to think about intellect augmentation as \\na systems engineering problem in which humans do not exist \\nsingularly but rather as part of a  larger system consisting of a \\nHuman using Language, A rtifacts,  and M ethodology in which  he \\nis Trained --which he calls the H-LAM/T system . Engelbart noted \\nthat whe n humans approach a problem solving task, we  have  \\nprocesses  or \"little steps or actions\" to call upon as we tackle \\nvarious parts of the problem. The entire problem -solving task is \\ncomposed of numerous processes in the form of a process', metadata={'source': 'data/data/Xia and Maes - 2013 - The design of artifacts for augmenting intellect.pdf', 'page': 0})]}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# break it down\n",
        "query = \"\"\"Favorite representations\n",
        "- notations (Leibniz), automata, graphs (Bret victor), car recliner button\n",
        "- keep reading design of everyday things\n",
        "- Going from 1 to 0 registers through analogy (Python)\n",
        "- Mendeleev and the periodic table\n",
        "\"\"\"\n",
        "llm_response = qa_chain(query)\n",
        "# process_llm_response(llm_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-e6fh6rNwz",
        "outputId": "4b8d1e0e-b039-4e21-c233-a6c308cc5e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Iron Pillar and Uncorrelated Ventures.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ],
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFf8D-rrN0I",
        "outputId": "19c63b88-33e2-4400-eede-f2678231eccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Databricks acquired Okera, a data governance platform with a focus on AI.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
            "new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
          ]
        }
      ],
      "source": [
        "query = \"What did databricks acquire?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5KETxphrN3d",
        "outputId": "4f4a7dfb-0f5b-4b72-b678-6def5d056d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Generative AI is a type of artificial intelligence that is used to create new content associated with a company, such as content for a website or ads. It can also be used to automate processes and workflows.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "new_articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n"
          ]
        }
      ],
      "source": [
        "query = \"What is generative ai?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692pHNkFrN5z",
        "outputId": "85124452-c208-4ec4-a35d-be28503ddc42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The CMA stands for the Competition and Markets Authority.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_articles/05-04-cma-generative-ai-review.txt\n",
            "new_articles/05-04-cma-generative-ai-review.txt\n"
          ]
        }
      ],
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPIhZWAR5n3X",
        "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('similarity', <langchain.vectorstores.chroma.Chroma at 0x7f9f7dc82aa0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_lp0_796P_-",
        "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "{context}\n",
            "\n",
            "Question: {question}\n",
            "Helpful Answer:\n"
          ]
        }
      ],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxVCnNi5h1-"
      },
      "source": [
        "## Deleteing the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xmepGJ2GAE",
        "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/chroma-collections.parquet (deflated 50%)\n",
            "  adding: db/index/ (stored 0%)\n",
            "  adding: db/index/index_metadata_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 5%)\n",
            "  adding: db/index/uuid_to_id_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 39%)\n",
            "  adding: db/index/index_59c51927-205d-4fd7-88d8-c7ba851bd2a5.bin (deflated 17%)\n",
            "  adding: db/index/id_to_uuid_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 35%)\n",
            "  adding: db/chroma-embeddings.parquet (deflated 29%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r db.zip ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl84qGQt5Wu5"
      },
      "outputs": [],
      "source": [
        "# To cleanup, you can delete the collection\n",
        "vectordb.delete_collection()\n",
        "vectordb.persist()\n",
        "\n",
        "# delete the directory\n",
        "!rm -rf db/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2r0ZIBPJp-K"
      },
      "source": [
        "## Starting again loading the db\n",
        "\n",
        "restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pc7CM_mTQAt",
        "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  db.zip\n",
            "   creating: db/\n",
            "  inflating: db/chroma-collections.parquet  \n",
            "   creating: db/index/\n",
            "  inflating: db/index/index_metadata_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
            "  inflating: db/index/uuid_to_id_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
            "  inflating: db/index/index_59c51927-205d-4fd7-88d8-c7ba851bd2a5.bin  \n",
            "  inflating: db/index/id_to_uuid_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
            "  inflating: db/chroma-embeddings.parquet  \n"
          ]
        }
      ],
      "source": [
        "!unzip db.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us3F8ZKeRiz2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK1nY4PkKYGo"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "396RyNbS4EXx",
        "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
          ]
        }
      ],
      "source": [
        "persist_directory = 'db'\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb2 = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding,\n",
        "                   )\n",
        "\n",
        "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3vkSxxYKCZ9"
      },
      "outputs": [],
      "source": [
        "# Set up the turbo LLM\n",
        "turbo_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsR60NH5KCfj"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWulTG0eKCfk"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDp-g2FtKCfk",
        "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pando raised $30 million in a Series B round, bringing its total raised to $45 million.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ],
      "source": [
        "# full example\n",
        "query = \"How much money did Pando raise?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fPl26c-TbWw"
      },
      "source": [
        "### Chat prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwyuhrpu5XqM",
        "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the users question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "{context}\n"
          ]
        }
      ],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcWXvSCHRvHO",
        "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{question}\n"
          ]
        }
      ],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/Users/danielgeorge/Documents/work/ml/hypolab/Synapse/server/dirty_index/test.txt'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    with open('/Users/danielgeorge/Documents/work/ml/hypolab/Synapse/server/dirty_index/test.txt', 'w') as f:\n",
        "        f.write('test')\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
